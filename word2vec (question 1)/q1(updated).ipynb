{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0 : Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import essential libraries needed\n",
    "\n",
    "##### Gensim is selected as it offers the ability to use pre-trained embeddings and compatibility with other libraries such as Scikit-learn and Pandas for downstream tasks in machine learning workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (0.26.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from gensim) (7.0.5)\n",
      "Requirement already satisfied: wrapt in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "#Installing packages\n",
    "!pip install datasets\n",
    "!pip install gensim\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\john1\\Desktop\\SC4002-NLP-G14\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "train_dataset = dataset['train'] \n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'effective but too-tepid biopic', 'if you sometimes like to go to the movies to have fun , wasabi is a good place to start .', \"emerges as something rare , an issue movie that's so honest and keenly observed that it doesn't feel like one .\"], 'label': [1, 1, 1, 1, 1]}\n",
      "{'text': ['compassionately explores the seemingly irreconcilable situation between conservative christian parents and their estranged gay and lesbian children .', 'the soundtrack alone is worth the price of admission .', 'rodriguez does a splendid job of racial profiling hollywood style--casting excellent latin actors of all ages--a trend long overdue .', \"beneath the film's obvious determination to shock at any cost lies considerable skill and determination , backed by sheer nerve .\", 'bielinsky is a filmmaker of impressive talent .'], 'label': [1, 1, 1, 1, 1]}\n",
      "{'text': ['lovingly photographed in the manner of a golden book sprung to life , stuart little 2 manages sweetness largely without stickiness .', 'consistently clever and suspenseful .', 'it\\'s like a \" big chill \" reunion of the baader-meinhof gang , only these guys are more harmless pranksters than political activists .', 'the story gives ample opportunity for large-scale action and suspense , which director shekhar kapur supplies with tremendous skill .', 'red dragon \" never cuts corners .'], 'label': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[:5])\n",
    "print(validation_dataset[:5])\n",
    "print(test_dataset[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing for Word2Vec Training\n",
    "\n",
    "##### We initialize a list to store the processed words from our training dataset. Each sentence is preprocessed by performing the following steps:\n",
    "\n",
    "##### Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long, uses ~gensim.utils.tokenise internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a list to hold processed sentences\n",
    "processed_sentences = []\n",
    "\n",
    "# Iterate over the text data in the training dataset\n",
    "for text in train_dataset['text']:\n",
    "        # Preprocess the sentence (tokenisation, lowercasing, removing punctuation)\n",
    "        processed_sentence = simple_preprocess(text)\n",
    "        \n",
    "        # Append the processed sentence to the list\n",
    "        processed_sentences.append(processed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'rock', 'is', 'destined', 'to', 'be', 'the', 'st', 'century', 'new', 'conan', 'and', 'that', 'he', 'going', 'to', 'make', 'splash', 'even', 'greater', 'than', 'arnold', 'schwarzenegger', 'jean', 'claud', 'van', 'damme', 'or', 'steven', 'segal'], ['the', 'gorgeously', 'elaborate', 'continuation', 'of', 'the', 'lord', 'of', 'the', 'rings', 'trilogy', 'is', 'so', 'huge', 'that', 'column', 'of', 'words', 'cannot', 'adequately', 'describe', 'co', 'writer', 'director', 'peter', 'jackson', 'expanded', 'vision', 'of', 'tolkien', 'middle', 'earth'], ['effective', 'but', 'too', 'tepid', 'biopic'], ['if', 'you', 'sometimes', 'like', 'to', 'go', 'to', 'the', 'movies', 'to', 'have', 'fun', 'wasabi', 'is', 'good', 'place', 'to', 'start'], ['emerges', 'as', 'something', 'rare', 'an', 'issue', 'movie', 'that', 'so', 'honest', 'and', 'keenly', 'observed', 'that', 'it', 'doesn', 'feel', 'like', 'one']]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 processed sentences\n",
    "print(processed_sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Preparing Word Embeddings\n",
    "\n",
    "### Gensim comes with several already pre-trained models, in the Gensim-data repository:\n",
    "\n",
    "- `conceptnet-numberbatch-17-06-300`\n",
    "- `word2vec-ruscorpora-300`\n",
    "- `word2vec-google-news-300`\n",
    "- `glove-wiki-gigaword-50`\n",
    "- `glove-wiki-gigaword-100`\n",
    "- `glove-wiki-gigaword-200`\n",
    "- `glove-wiki-gigaword-300`\n",
    "- `glove-twitter-25`\n",
    "- `glove-twitter-50`\n",
    "- `glove-twitter-100`\n",
    "- `glove-twitter-200`\n",
    "- `__testing_word2vec-matrix-synopsis`\n",
    "\n",
    "##### In the model names, the numbers refer to the dimensionality of the word vectors (embeddings) for each pre-trained model, this means that higher dimensions capture more complex relationships between words but require more memory and computational resources.\n",
    "\n",
    "\n",
    "##### Model name examples:\n",
    "\n",
    "- **`word2vec-google-news-300`**: A Word2Vec model trained on Google News, providing embeddings with 300 dimensions.\n",
    "- **`glove-twitter-100`**: A GloVe model trained on Twitter data, with 100-dimensional embeddings specialized for social media language.\n",
    "\n",
    "##### We will explore a few of these pre trained models to see which models will do better in migitating number of OOV words in our dataset. To keep it fair, we will select the models with the highest dimentions from each category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Specify path to save models\n",
    "save_paths = {\n",
    "    'word2vec_ruscorpora_300': './word2vec_ruscorpora_300.model',\n",
    "    'word2vec_google_300': './word2vec_google_news_300.model',\n",
    "    'glove_wiki_300': './glove_wiki_gigaword_300.model',\n",
    "    'glove_twitter_200': './glove_twitter_200.model'\n",
    "}\n",
    "\n",
    "# Download and save each model, will take up to few minutes\n",
    "word2vec_ruscorpora_300 = api.load('word2vec-ruscorpora-300')\n",
    "word2vec_ruscorpora_300.save(save_paths['word2vec_ruscorpora_300'])\n",
    "\n",
    "word2vec_google_300 = api.load('word2vec-google-news-300')\n",
    "word2vec_google_300.save(save_paths['word2vec_google_300'])\n",
    "\n",
    "glove_wiki_300 = api.load('glove-wiki-gigaword-300')\n",
    "glove_wiki_300.save(save_paths['glove_wiki_300'])\n",
    "\n",
    "glove_twitter_200 = api.load('glove-twitter-200')\n",
    "glove_twitter_200.save(save_paths['glove_twitter_200'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded from local files.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load models from saved files\n",
    "word2vec_ruscorpora_300 = KeyedVectors.load('./word2vec_ruscorpora_300.model')\n",
    "word2vec_google_300 = KeyedVectors.load('./word2vec_google_news_300.model')\n",
    "glove_wiki_300 = KeyedVectors.load('./glove_wiki_gigaword_300.model')\n",
    "glove_twitter_200 = KeyedVectors.load('./glove_twitter_200.model')\n",
    "\n",
    "print(\"Models loaded from local files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1(a): Calculate vocabulary size from processed sentences previously in part 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in training data: 16288\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the list of processed sentences and get unique words\n",
    "train_vocab = set(word for sentence in processed_sentences for word in sentence)\n",
    "\n",
    "# (1a) Vocabulary size\n",
    "vocab_size = len(train_vocab)\n",
    "print(\"Size of vocabulary in training data:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1(b) Identify out-of-vocabulary (OOV) words while taking into account various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in word2vec_ruscorpora_300 model: 184973\n",
      "Number of OOV words: 16288\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size of ruscorpora model\n",
    "word2vec_ruscorpora_300_vocab_size = len(word2vec_ruscorpora_300.key_to_index)\n",
    "print(\"Size of vocabulary in word2vec_ruscorpora_300 model:\", word2vec_ruscorpora_300_vocab_size)\n",
    "\n",
    "# (b) Count OOV words\n",
    "oov_words = [word for word in train_vocab if word not in word2vec_ruscorpora_300]\n",
    "oov_count = len(oov_words)\n",
    "print(\"Number of OOV words:\", oov_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in word2vec_google_300 model: 3000000\n",
      "Number of OOV words: 1473\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size of word2vec_google_300 model\n",
    "word2vec_google_300_vocab_size = len(word2vec_google_300.key_to_index)\n",
    "print(\"Size of vocabulary in word2vec_google_300 model:\", word2vec_google_300_vocab_size)\n",
    "\n",
    "# (b) Count OOV words\n",
    "oov_words = [word for word in train_vocab if word not in word2vec_google_300]\n",
    "oov_count = len(oov_words)\n",
    "print(\"Number of OOV words:\", oov_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in glove_wiki_300 model: 400000\n",
      "Number of OOV words: 580\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size of glove_wiki_300 model\n",
    "glove_wiki_300_vocab_size = len(glove_wiki_300.key_to_index)\n",
    "print(\"Size of vocabulary in glove_wiki_300 model:\", glove_wiki_300_vocab_size)\n",
    "\n",
    "# (b) Count OOV words\n",
    "oov_words = [word for word in train_vocab if word not in glove_wiki_300]\n",
    "oov_count = len(oov_words)\n",
    "print(\"Number of OOV words:\", oov_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary in glove_twitter_200 model: 1193514\n",
      "Number of OOV words: 1473\n"
     ]
    }
   ],
   "source": [
    "# Vocabulary size of glove_twitter_200 model\n",
    "glove_twitter_200_vocab_size = len(glove_twitter_200.key_to_index)\n",
    "print(\"Size of vocabulary in glove_twitter_200 model:\", glove_twitter_200_vocab_size)\n",
    "\n",
    "# (b) Count OOV words\n",
    "oov_words = [word for word in train_vocab if word not in glove_twitter_200]\n",
    "oov_count = len(oov_words)\n",
    "print(\"Number of OOV words:\", oov_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From this analysis, we can tell that glove_wiki_300 models is the best performing model on the training dataset, as it has a smaller vocabulary as compared to the other models, but still produced the least number of OOV words. We will use the glove_wiki_300 model from now onwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare the Embedding Matrix\n",
    "\n",
    "##### Create an embedding matrix for later parts, each row corresponds to the embedding of a specific word in the training vocabulary. For OOV words, we will use a zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding dimension\n",
    "embedding_dim = glove_wiki_300.vector_size\n",
    "\n",
    "# Get the size of the vocabulary\n",
    "train_vocab_size = len(train_vocab)  # Make sure train_vocab is a set or list\n",
    "\n",
    "# Initialize the embedding matrix\n",
    "embedding_matrix = np.zeros((train_vocab_size, embedding_dim))\n",
    "\n",
    "# Create a mapping of each word in train_vocab to an index\n",
    "word_to_index = {word: idx for idx, word in enumerate(train_vocab)}\n",
    "\n",
    "# Populate the embedding matrix\n",
    "for word, idx in word_to_index.items():\n",
    "    if word in glove_wiki_300:\n",
    "        embedding_matrix[idx] = glove_wiki_300[word]\n",
    "    else:\n",
    "        # Use zero vector for OOV words\n",
    "        embedding_matrix[idx] = np.zeros(embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the embedding matrix: (16288, 300)\n",
      "First 5 embeddings:\n",
      "[[ 0.24978     0.15938     0.19845    ...  1.00559998  0.19495\n",
      "   0.31422001]\n",
      " [ 0.26120999  0.31194001 -0.14826    ... -0.67054999 -0.28485\n",
      "   0.13755   ]\n",
      " [ 0.038951   -0.12122    -0.29510999 ...  0.50962001 -0.68910003\n",
      "  -0.25566   ]\n",
      " [-0.61173999  0.34871    -0.92996001 ...  0.31099999  0.91194999\n",
      "  -0.31082001]\n",
      " [ 0.63892001  0.027604    0.13714001 ...  0.086945   -0.35929\n",
      "   0.33945   ]]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the embedding matrix\n",
    "print(\"Shape of the embedding matrix:\", embedding_matrix.shape)\n",
    "\n",
    "# Print the first 5 embeddings\n",
    "print(\"First 5 embeddings:\")\n",
    "print(embedding_matrix[:5])  # Adjust the slice as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the' is in the vocabulary.\n",
      "'rock' is in the vocabulary.\n",
      "'is' is in the vocabulary.\n",
      "'destined' is in the vocabulary.\n",
      "'to' is in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Check whether words from training set is in th embedding\n",
    "words_to_check = ['the', 'rock', 'is', 'destined', 'to']\n",
    "\n",
    "for word in words_to_check:\n",
    "    if word in word_to_index:\n",
    "        print(f\"'{word}' is in the vocabulary.\")\n",
    "    else:\n",
    "        print(f\"'{word}' is not in the vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed first sentence from embeddings:\n",
      "the rock is destined to be the st century new conan and that he going to make splash even greater than arnold schwarzenegger jean claud van damme or steven segal\n"
     ]
    }
   ],
   "source": [
    "# Get the first sentence from processed_sentences\n",
    "first_sentence = processed_sentences[0]  # Assume this is a list of words like ['this', 'movie', 'was', 'great']\n",
    "\n",
    "# Initialize an empty list to hold the words\n",
    "reconstructed_sentence = []\n",
    "\n",
    "# Loop through each word in the first sentence\n",
    "for word in first_sentence:\n",
    "    if word in word_to_index:  # Check if the word is in vocabulary\n",
    "        index = word_to_index[word]  # Get the index of the word\n",
    "        embedding = embedding_matrix[index]  # Retrieve the embedding\n",
    "        reconstructed_sentence.append(word)  # Add the word back to the sentence\n",
    "\n",
    "# Join the words to form the reconstructed sentence\n",
    "reconstructed_sentence_str = ' '.join(reconstructed_sentence)\n",
    "\n",
    "# Output the reconstructed sentence\n",
    "print(\"Reconstructed first sentence from embeddings:\")\n",
    "print(reconstructed_sentence_str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1(c) Implementing a strategy to handle OOV words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strategy 1: Calculates a sentence vector by averaging in-vocabulary word embeddings, effectively ignoring OOV words.\n",
    "\n",
    "##### This approach: \n",
    "\n",
    "- This approach creates a vector representation for a sentence by taking the average of the word embeddings for all in-vocabulary words in the sentence.\n",
    "- By ignoring OOV words (words without embeddings), the strategy reduces the potential impact of missing vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence vector: [-1.53414346e-02 -9.83752590e-03 -5.52846305e-02 -9.99514684e-02\n",
      "  3.01311947e-02  1.24417685e-01  3.51512656e-02 -8.86158645e-02\n",
      "  5.73788676e-03 -1.08949292e+00  1.85584605e-01 -5.60377762e-02\n",
      " -9.68933664e-03  1.03667580e-01  6.70564100e-02  5.24014123e-02\n",
      " -1.68635145e-01 -3.12670171e-02  4.08079997e-02  7.22704735e-03\n",
      "  3.13387737e-02  1.88141063e-01  1.58004612e-01  7.59189427e-02\n",
      " -1.81370601e-01  7.10277483e-02  1.25491977e-01 -1.95886679e-02\n",
      "  5.73181361e-02  2.00815815e-02  7.70360678e-02  2.06905693e-01\n",
      " -2.18780972e-02  8.56238753e-02 -7.37673342e-01 -2.27190293e-02\n",
      " -5.49495742e-02 -4.15924937e-02  4.21326384e-02 -2.35538818e-02\n",
      " -1.13561312e-02 -8.40994269e-02 -1.04256593e-01 -5.45769371e-02\n",
      "  1.49288565e-01  9.94461104e-02  1.03147775e-01  7.92050287e-02\n",
      " -6.59514889e-02 -2.47636642e-02  3.56394015e-02 -1.05243325e-01\n",
      " -2.51182504e-02  8.16771686e-02  3.56279649e-02  1.22403152e-01\n",
      " -1.23865858e-01  3.06245804e-01  1.17730126e-01 -1.11946091e-01\n",
      "  2.58531924e-02 -8.46989006e-02  1.76545903e-01  1.06036663e-03\n",
      "  1.09659350e-02 -2.65865177e-01  5.88165261e-02  3.83106084e-03\n",
      "  3.42997760e-02  7.72191538e-03  2.88854633e-02 -3.56411934e-02\n",
      "  7.57326186e-02  1.12929620e-01 -5.50059639e-02  2.19766493e-03\n",
      "  6.60174936e-02  1.60826176e-01 -5.05217500e-02 -2.88286377e-02\n",
      " -1.36268929e-01  4.42325138e-02  1.14377297e-01  1.62991304e-02\n",
      " -3.05080693e-02  9.89307836e-02 -5.70802353e-02  2.57775217e-01\n",
      " -3.92595939e-02 -5.60176969e-02 -1.29252002e-01  1.86086148e-01\n",
      " -9.42192078e-02 -1.17096946e-01 -1.04097970e-01 -1.20538630e-01\n",
      " -7.18460828e-02 -1.03698269e-01 -3.21037546e-02 -3.56618017e-01\n",
      " -7.78709119e-03  1.18404262e-01 -9.00181569e-03  6.63728416e-02\n",
      " -7.16381893e-02  8.08281228e-02  4.22172137e-02  7.10694566e-02\n",
      " -1.94097627e-02  5.92433801e-03 -9.49752256e-02  9.34937689e-03\n",
      " -4.40370217e-02 -1.10874534e-01  8.55876729e-02  8.09762031e-02\n",
      "  1.00458916e-02 -7.73019670e-03  7.20388489e-03 -2.78795242e-01\n",
      " -8.17115307e-02  3.36944312e-02 -8.12121332e-02  4.06636968e-02\n",
      " -7.29546836e-03  2.81310361e-02  1.95928544e-01  1.12501062e-01\n",
      "  3.82951610e-02 -1.31533900e-02  8.46839920e-02  5.92345260e-02\n",
      "  9.03140306e-02  6.14453666e-02  7.76378438e-02 -1.60005949e-02\n",
      "  7.91651309e-02 -1.03831194e-01 -8.46160427e-02  1.37154162e-01\n",
      "  4.02416326e-02  3.76755521e-02  8.68001282e-02  7.88250118e-02\n",
      " -1.75798193e-01 -1.82067916e-01  7.82436430e-02  2.95810192e-03\n",
      " -2.50572056e-01  2.14351360e-02  2.88477927e-01  6.66572005e-02\n",
      "  6.30342960e-03 -6.06902987e-02  2.28487343e-01  4.86507565e-02\n",
      " -7.23537728e-02  1.75764579e-02  2.94871684e-02  6.23402977e-03\n",
      "  1.00057069e-02 -9.90480091e-03  4.71778996e-02 -4.92786728e-02\n",
      " -1.98309347e-02  2.78658997e-02  3.37747931e-02  6.11188635e-02\n",
      "  1.51792960e-02  9.70214903e-02  1.41224399e-01  2.57034022e-02\n",
      " -4.21124727e-01  5.27798347e-02  5.62264062e-02  2.03849990e-02\n",
      " -1.28560988e-02 -4.59863618e-02 -4.37239185e-02  2.14221612e-01\n",
      "  2.93980651e-02  2.23111197e-01  1.00271530e-01 -1.70661323e-02\n",
      "  1.58891045e-02 -1.38075827e-02 -2.70417482e-01  7.49709234e-02\n",
      "  7.84770325e-02  1.39554650e-01 -3.16866413e-02  1.74420029e-01\n",
      "  1.89221039e-01  3.98270600e-02  7.69042177e-03 -8.98709297e-02\n",
      " -1.37998266e-02 -4.65808176e-02  3.70749794e-02  5.36733260e-03\n",
      "  8.29033673e-01 -3.53511944e-02  4.56959024e-05 -6.53163344e-02\n",
      "  7.47228935e-02  1.06582657e-01 -7.89906308e-02  1.40596151e-01\n",
      " -1.28247783e-01 -1.52263090e-01 -5.94525971e-02  9.41580068e-03\n",
      "  1.31512225e-01 -6.44470006e-02  4.17959653e-02  7.36396685e-02\n",
      "  9.30669755e-02  9.81680006e-02 -3.48829734e-03 -1.20636307e-01\n",
      "  1.64326951e-01 -1.49487006e-02 -1.15138799e-01 -4.42712754e-02\n",
      " -1.26934558e-01 -1.51383653e-01  9.97672006e-02  1.22884169e-01\n",
      " -2.61291098e-02 -1.07524052e-01  5.54967001e-02  1.67678386e-01\n",
      " -4.49482687e-02 -7.08784983e-02  3.68696675e-02  1.10556632e-01\n",
      "  9.78430733e-02  1.65892407e-01 -7.69235417e-02  7.57827908e-02\n",
      " -8.95575583e-02 -6.79080095e-03  2.02744186e-01  6.58421293e-02\n",
      " -4.11678910e-01  6.78727552e-02  1.02304704e-01 -1.32889941e-01\n",
      " -9.50054303e-02 -7.25969374e-02  1.43096624e-02 -8.82750377e-02\n",
      " -3.67011577e-02 -1.40718026e-02  2.91791290e-01 -1.17159508e-01\n",
      "  1.26232609e-01 -1.71918124e-01  1.27598301e-01 -4.10542600e-02\n",
      "  7.59173408e-02 -1.01018645e-01  5.11622652e-02  9.27320570e-02\n",
      " -4.26018238e-02 -1.06892146e-01 -4.75605316e-02 -5.02349585e-02\n",
      "  4.98497821e-02  3.55417691e-02  1.19272657e-02 -1.29828721e-01\n",
      "  2.61600912e-02  6.79183751e-02  4.80677038e-02  2.12507233e-01\n",
      " -1.35091782e+00 -1.18957400e-01  2.54011303e-01  3.79361287e-02\n",
      " -1.56738222e-01  1.22284377e-02  8.47359672e-02  3.00175343e-02\n",
      " -3.81425992e-02  1.57539383e-01 -6.45016059e-02  1.20791085e-01\n",
      " -5.79019003e-02  3.15163061e-02 -4.52941610e-03 -1.70028239e-01\n",
      "  9.83257070e-02 -4.58286423e-03  7.22390190e-02 -5.03623066e-03\n",
      "  4.77693342e-02 -9.41030160e-02 -6.13452904e-02  1.14880227e-01]\n"
     ]
    }
   ],
   "source": [
    "def get_word_vector(word):\n",
    "    \"\"\"Return the GloVe vector if the word exists, otherwise return a zero vector.\"\"\"\n",
    "    return glove_wiki_300[word] if word in glove_wiki_300 else np.zeros(embedding_dim)\n",
    "\n",
    "def sentence_vector(sentence):\n",
    "    \"\"\"Calculate the average vector for a sentence by averaging in-vocabulary word vectors.\"\"\"\n",
    "    vectors = [get_word_vector(word) for word in sentence if get_word_vector(word) is not None]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)\n",
    "\n",
    "# Example usage\n",
    "sample_sentence = processed_sentences[0]  # Use the first processed sentence as an example\n",
    "sentence_vec = sentence_vector(sample_sentence)\n",
    "print(\"Sentence vector:\", sentence_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strategy 2: Using subword embeddings, such as those generated by FastText.\n",
    "\n",
    "##### This approach:\n",
    "\n",
    "-  Address the OOV problem by creating word embeddings based on subword components (like character n-grams).\n",
    "- This allows the model to create a vector representation for a word even if it hasn’t encountered that exact word in the training data.\n",
    "- For instance, if the model has seen “exciting” and “amazing” but not “excited,” it can still generate a meaningful vector for “excited” based on its subword parts.\n",
    "\n",
    "##### For this part, download the fasttext model from this link: https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec and place it in the project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Using cached fasttext-0.9.3.tar.gz (73 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pybind11>=2.2 (from fasttext)\n",
      "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from fasttext) (65.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\john1\\desktop\\sc4002-nlp-g14\\.venv\\lib\\site-packages (from fasttext) (1.26.4)\n",
      "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (pyproject.toml): started\n",
      "  Building wheel for fasttext (pyproject.toml): finished with status 'error'\n",
      "Failed to build fasttext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for fasttext (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [31 lines of output]\n",
      "      C:\\Users\\john1\\AppData\\Local\\Temp\\pip-build-env-1qp3qxl6\\overlay\\Lib\\site-packages\\setuptools\\dist.py:495: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Usage of dash-separated 'description-file' will not be supported in future\n",
      "              versions. Please use the underscore name 'description_file' instead.\n",
      "      \n",
      "              By 2025-Mar-03, you need to update your project and remove deprecated calls\n",
      "              or your builds will no longer be supported.\n",
      "      \n",
      "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        opt = self.warn_dash_deprecation(opt, section)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-311\\fasttext\n",
      "      copying python\\fasttext_module\\fasttext\\FastText.py -> build\\lib.win-amd64-cpython-311\\fasttext\n",
      "      copying python\\fasttext_module\\fasttext\\__init__.py -> build\\lib.win-amd64-cpython-311\\fasttext\n",
      "      creating build\\lib.win-amd64-cpython-311\\fasttext\\util\n",
      "      copying python\\fasttext_module\\fasttext\\util\\util.py -> build\\lib.win-amd64-cpython-311\\fasttext\\util\n",
      "      copying python\\fasttext_module\\fasttext\\util\\__init__.py -> build\\lib.win-amd64-cpython-311\\fasttext\\util\n",
      "      creating build\\lib.win-amd64-cpython-311\\fasttext\\tests\n",
      "      copying python\\fasttext_module\\fasttext\\tests\\test_configurations.py -> build\\lib.win-amd64-cpython-311\\fasttext\\tests\n",
      "      copying python\\fasttext_module\\fasttext\\tests\\test_script.py -> build\\lib.win-amd64-cpython-311\\fasttext\\tests\n",
      "      copying python\\fasttext_module\\fasttext\\tests\\__init__.py -> build\\lib.win-amd64-cpython-311\\fasttext\\tests\n",
      "      running build_ext\n",
      "      building 'fasttext_pybind' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for fasttext\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (fasttext)\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load model for usage, will take a couple of minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = KeyedVectors.load_word2vec_format('./wiki.en.vec', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of OOV words: 239\n"
     ]
    }
   ],
   "source": [
    "# Check each word in the processed sentences against the FastText model\n",
    "oov_count = 0\n",
    "\n",
    "for word in train_vocab:\n",
    "    if word not in fasttext_model:\n",
    "        oov_count += 1\n",
    "\n",
    "# Output the total number of OOV words\n",
    "print(\"Number of OOV words:\", oov_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using fastext, number of OOV words is much lesser"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
